---
title: "IU length for he"
author: "Lu Liu"
date: "`r format(Sys.Date(), '%B %d, %Y')`"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, echo=FALSE}
library(knitr)
# set global chunk options: images will be 7x5 inches
knitr::opts_chunk$set(fig.width=7, fig.height=5)
options(digits = 4)
```

```{r, include=FALSE}
# for debugging latex
options(tinytex.verbose = TRUE)
```

```{r}
library(tidyverse)
library(tidymodels)
library(corrr)
library(rstan)
library(tidyr)
library(MASS)
library(fitdistrplus)
library(bayestestR)
library(prevtoinc)
library("bayesplot")
library("ggplot2")
library("rstanarm")
library(scatterplot3d)
library(extraDistr)
library(actuar)
```
## He

### Load the data

```{r}
load("/Users/lu/Desktop/Winter_2023/sb corpus/sbc.Rdata")

he <- sbc[sbc$transcript == "he", ]

hist(he$unitLen)
summary(he$unitLen)
```
### Possion 

#### Regular Possion

```{r}
data <- he$unitLen
# length <- data[["unitLen"]]

length_data <- list(
  N = 2200,
  unit_length = data
)

stan_fit <- stan(
  file = "He_length_poisson.stan",
  data = length_data,
  chain = 4
)

```

```{r}
print(stan_fit)
```

#### Truncated Possion 

```{r}
# truncated
data <- he$unitLen
# length <- data[["unitLen"]]

length_data <- list(
  N = 2200,
  unit_length = data
)

stan_poisson_length <- stan(
  file = "He_length_Tpoisson.stan",
  data = length_data,
  chain = 4
)
```

```{r}
print(stan_fit_T)

list_of_draws <- extract(stan_fit_T)
names(list_of_draws)

list_of_draws$y_tilde
length(list_of_draws$y_tilde)

hist(list_of_draws$length_rep)
```

#### generate

```{r}
set.seed(3435)
pois <- fitdist(data, 'pois', method = 'mle')
pois["estimate"]
```
#### Some plot

```{r}
plot(stan_fit)
traceplot(stan_fit)
```

```{r}
samples <- extract(stan_fit, permuted = TRUE)
samples
```

```{r}
# testing for overdispersion

library(AER)
library(bayesplot)
library(rstanarm)

ppc_hist(y = he$unitLen, yrep = list_of_draws$length_rep[1:5, ], binwidth = 2.5)

ppc_dens_overlay(he$unitLen, list_of_draws$length_rep[1:50, ])
```

```{r}
plot(list_of_draws$mean_length_rep, (list_of_draws$sd_length_rep)^2)
abline(lm((list_of_draws$sd_length_rep)^2 ~ list_of_draws$mean_length_rep), col = "red")

```

```{r}
vm1 <- glm(list_of_draws$sd_length_rep^2 ~ -1 + list_of_draws$mean_length_rep, family = "poisson")

dispersiontest(vm1)
# f(u) = u^2
vm2 <- lm(list_of_draws$sd_length_rep^2 ~ -1 + list_of_draws$mean_length_rep^2)
```

### Negative Binomial 
```{r}
data <- he$unitLen
# length <- data[["unitLen"]]

length_data <- list(
  N = 2200,
  unit_length = data
)

stan_NB_length <- stan(
  file = "He_length_NB.stan",
  data = length_data,
  chain = 4
)

```


```{r}
print(stan_fit_T)

list_of_draws2 <- extract(stan_fit_T)
names(list_of_draws2)

list_of_draws$y_tilde
# length(list_of_draws$y_tilde)

# hist(list_of_draws$length_rep)
```

```{r}
set.seed(3435)
nbinom <- fitdist(data, 'nbinom')
nbinom
```

```{r}

hist(he$unitLen)



```

### place | length Negative Binomial 
```{r}
unitlen_data <- he$unitLen
place_data <- he$place
# length <- data[["unitLen"]]

length_data <- list(
  N = 2200,
  place = place_data,
  unit_length = unitlen_data
)

place_length_nb <- stan(
  file = "He_place|length_NB.stan",
  data = length_data,
  chain = 4
)

```

```{r}
print(stan_fit_T)
```

```{r}
sum(is.na(place_data))
hist(place_data, prob=TRUE)
fit <- fitdist(place_data, "nbinom")
fit
fitNB = dnbinom(2200, size=13.407 , mu=2.502)

```
### MAP test negbin and poisson 
Take both the Poisson and the negative binomial models we got, and use the maximum a posteriori (MAP) estimates.

#### Poisson
```{r}
# empirical pmf
len_emp <- epmf(he$unitLen)
plot(len_emp, type = "o")

# MAP 
# poisson parameter
set.seed(43)
print(stan_poisson_length, pars=c("lambda"))

# generate
poisson_pos <- rpois(2200, 9.23)
map_estimate(poisson_pos)

plot(density(poisson_pos))
abline(v = map_estimate(poisson_pos), col = "red")
lines(len_emp, col = "blue")
```
#### NB
```{r}
# MAP 
# NB parameter
set.seed(43)
print(stan_NB_length, pars=c("mu", "phi"))

# generate
NB_pos <- rnbinom(2200, size = 36.53, mu = 9.23) 
map_estimate(NB_pos)

plot(density(NB_pos), ylim = range(len_emp))
abline(v = map_estimate(NB_pos), col = "red")
lines(len_emp, col = "blue")

# question: fluctuate a lot? close enough, generalised Poisson?
```

### Posterior predictive check for the joint model 

#### place | length

```{r}

print(place_length_nb)
```

```{r}
# seperate 
generated_quantities <- extract(place_length_nb, pars = c("length_rep", "place_rep"))
ppc_dens_overlay(he$unitLen, generated_quantities$length_rep[1:50,])
ppc_dens_overlay(he$place, generated_quantities$place_rep[1:50,])

```   

#### generate quantities for place | length

```{r}
nb_lambda_he <- extract(place_length_nb, pars = c("lambda"))
nb_phi_he <- extract(place_length_nb, pars = c("phi"))
nb_mu_he <- extract(place_length_nb, pars = c("mu"))

DataList <- vector("list", length = 4000)

# iterate through 4000 times
for (i in 1:4000) {
  
  # for each iteration creates a list
  iterationList <- vector("list", length = 2200)
  
  # generate length
  nb_length <- rnbinom(2200, size = nb_phi_he$phi[i], mu = nb_mu_he$mu[i])
  nb_length0 <- nb_length[nb_length > 0]
  diff1 <- (2200 - length(nb_length0))
  
  while (diff1 > 0) {
    nb_length <- rnbinom(diff1, size = nb_phi_he$phi[i], mu = nb_mu_he$mu[i])
    nb_length0 <- c(nb_length0, nb_length[nb_length > 0])
    diff1 <- (2200 - length(nb_length0))
  }
  
  # generate place
  for (length_val in nb_length) {
      
    nb_place <- rpois(1, nb_lambda_he$lambda[i])
    nb_place0 <- nb_place[nb_place > 0 & nb_place < length_val]
    diff <- (1 - length(nb_place0))
      
    while (diff > 0) {
      nb_place <- rpois(diff, nb_lambda_he$lambda[i])
      nb_place0 <- c(nb_place0, nb_place[nb_place > 0 || nb_place < length_val])
      diff <- (1 - length(nb_place0))
    }
    iterationList[[length_val]] <- c(nb_place0)
  }
  DataList[[i]] <- iterationList
}

```


```{r}
nb_lambda_he <- extract(place_length_nb, pars = c("lambda"))
nb_phi_he <- extract(place_length_nb, pars = c("phi"))
nb_mu_he <- extract(place_length_nb, pars = c("mu"))

he_final = data.frame()
# iterate through 4000 times
for (i in 1:4000) {
  
  
  # generate length
  nb_length <- rztnbinom(2200, size = nb_phi_he$phi[i], 
                         prob = nb_phi_he$phi[i] / (nb_phi_he$phi[i] + nb_mu_he$mu[i]))
  
  nb_place <- c()
  for (length_val in nb_length) {
    nb_place <- c(nb_place, rtpois(1, nb_lambda_he$lambda[i], a = 0, b = length_val))

  }
  he_generated <- data.frame(nb_length, nb_place)
  he_final <- rbind(he_final, he_generated)
}

```

#### Visualization of he final

```{r}
all_df <- data.frame(nb_length = numeric(), nb_place = numeric(), n.x = numeric(), n.y = numeric())
num_iterations <- nrow(he_final) / 2200

for (i in 1:num_iterations) {
  start_index <- (i - 1) * 2200 + 1
  end_index <- i * 2200
  
  subset_data <- he_final[start_index:end_index, ] %>% group_by(nb_length, nb_place) %>% count
  
  subset <- subset_data[subset_data$nb_length < 15 & subset_data$nb_length > 1,]
  result <- aggregate(n ~ nb_length, data = subset, FUN = sum)
  
  merged_df <- merge(subset, result, by = "nb_length")
  
  all_df <- rbind(all_df, merged_df)
}

group <- he[c("unitLen", "place")]
colnames(group) <- c("nb_length", "nb_place")

group <- group %>% group_by(nb_length, nb_place) %>% count
subset <- group[group$nb_length < 15 & group$nb_length > 1,]
result <- aggregate(n ~ nb_length, data = subset, FUN = sum)
result <- merge(subset, result, by = "nb_length")

p <- ggplot(data = all_df, aes(x = nb_place, y = n.x/n.y)) +
    geom_point()
  
p + facet_grid(nb_length ~ .) + geom_point(data = result, color = "red") + facet_grid(nb_length ~ .)

```


### Poisson Poisson
```{r}
unitlen_data <- he$unitLen
place_data <- he$place

length_data <- list(
  N = 2200,
  place = place_data,
  unit_length = unitlen_data
)

he_pois_pois <- stan(
  file = "He_Pois_Pois.stan",
  data = length_data,
  chain = 4
)
```

```{r}
nb_lambda1_he <- extract(he_pois_pois, pars = c("lambda1"))
nb_lambda2_he <- extract(he_pois_pois, pars = c("lambda2"))

he_pois_final = data.frame()
# iterate through 4000 times
for (i in 1:2) {
  
  
  # generate length
  nb_length <- rtpois(2200, nb_lambda1_he$lambda1[i], a = 0)
  
  nb_place <- c()
  for (length_val in nb_length) {
    nb_place <- c(nb_place, rtpois(1, nb_lambda2_he$lambda2[i], a = 0, b = length_val))

  }
  he_generated <- data.frame(nb_length, nb_place)
  he_pois_final <- rbind(he_pois_final, he_generated)
}

```

```{r}
hist(he$unitLen)
hist(he_pois_final$nb_length[2200:4400])

```

### Generalzied Poisson 
```{r}
unitlen_he <- he$unitLen
place_he <- he$place

he_data <- list(
  N = length(unitlen_he),
  place = place_he,
  unit_length = unitlen_he
)

he_genpois <- stan(
  file = "gen_pois.stan",
  data = he_data,
  chain = 4
)

summary(he_genpois)
```


## She

### Load the data
```{r}
load("/Users/lu/Desktop/Winter_2023/sb corpus/sbc.Rdata")

she <- sbc[sbc$transcript == "she", ]

hist(she$unitLen)
hist(he$unitLen)
summary(she$unitLen)
```

### stan model 
```{r}
unitlen_she <- she$unitLen
place_she <- she$place

she_data <- list(
  N = length(she$unitLen),
  place = place_she,
  unit_length = unitlen_she
)

place_length_nb_she <- stan(
  file = "He_place|length_NB.stan",
  data = she_data,
  chain = 4
)
```
### generate quantities

```{r}
nb_lambda_she <- extract(place_length_nb_she, pars = c("lambda"))
nb_phi_she <- extract(place_length_nb_she, pars = c("phi"))
nb_mu_she <- extract(place_length_nb_she, pars = c("mu"))

she_final = data.frame()
# iterate through 4000 times
for (i in 1:4000) {
  
  
  # generate length
  nb_length <- rztnbinom(length(she$unitLen), size = nb_phi_she$phi[i], 
                         prob = nb_phi_she$phi[i] / (nb_phi_she$phi[i] + nb_mu_she$mu[i]))
  
  nb_place <- c()
  for (length_val in nb_length) {
    nb_place <- c(nb_place, rtpois(1, nb_lambda_she$lambda[i], a = 0, b = length_val))

  }
  she_generated <- data.frame(nb_length, nb_place)
  she_final <- rbind(she_final, she_generated)
}

```

### Visualization of he final

```{r}
all_df <- data.frame(nb_length = numeric(), nb_place = numeric(), n.x = numeric(), n.y = numeric())
num_iterations <- nrow(she_final) / length(she$unitLen)

for (i in 1:num_iterations) {
  start_index <- (i - 1) * length(she$unitLen) + 1
  end_index <- i * length(she$unitLen)
  
  subset_data <- she_final[start_index:end_index, ] %>% group_by(nb_length, nb_place) %>% count
  
  subset <- subset_data[subset_data$nb_length < 15 & subset_data$nb_length > 1,]
  result <- aggregate(n ~ nb_length, data = subset, FUN = sum)
  
  merged_df <- merge(subset, result, by = "nb_length")
  
  all_df <- rbind(all_df, merged_df)
}

group <- she[c("unitLen", "place")]
colnames(group) <- c("nb_length", "nb_place")

group <- group %>% group_by(nb_length, nb_place) %>% count
subset <- group[group$nb_length < 15 & group$nb_length > 1,]
result <- aggregate(n ~ nb_length, data = subset, FUN = sum)
result <- merge(subset, result, by = "nb_length")

p <- ggplot(data = all_df, aes(x = nb_place, y = n.x/n.y)) +
    geom_point()
  
p + facet_grid(nb_length ~ .) + geom_point(data = result, color = "red") + facet_grid(nb_length ~ .)

```

## They
```{r}
they <- sbc[sbc$transcript == "they", ]
summary(they$unitLen)
hist(they$unitLen)
```

```{r}
unitlen_they <- they$unitLen
place_they <- they$place

they_data <- list(
  N = length(unitlen_they),
  place = place_they,
  unit_length = unitlen_they
)

place_length_nb_they <- stan(
  file = "He_place|length_NB.stan",
  data = they_data,
  chain = 4
)
```

## I
```{r}
I <- sbc[sbc$transcript == "I", ]
summary(I$unitLen)
```

```{r}
unitlen_I <- I$unitLen
place_I <- I$place

I_data <- list(
  N = 8109,
  place = place_I,
  unit_length = unitlen_I
)

place_length_nb_I <- stan(
  file = "He_place|length_NB.stan",
  data = I_data,
  chain = 4
)

```


## Would

### Load the data
```{r}

would <- sbc[sbc$transcript == "would", ]

hist(would$unitLen)
hist(he$unitLen)
summary(would$unitLen)
```

### stan model 
```{r}
unitlen_would <- would$unitLen
place_would <- would$place

would_data <- list(
  N = length(unitlen_would),
  place = place_would,
  unit_length = unitlen_would
)

place_length_nb_would <- stan(
  file = "He_place|length_NB.stan",
  data = would_data,
  chain = 4
)
```

### generate quantities

```{r}
nb_lambda_would <- extract(place_length_nb_would, pars = c("lambda"))
nb_phi_would <- extract(place_length_nb_would, pars = c("phi"))
nb_mu_would <- extract(place_length_nb_would, pars = c("mu"))

would_final = data.frame()
# iterate through 4000 times
for (i in 1:4000) {
  
  
  # generate length
  nb_length <- rztnbinom(length(unitlen_would), size = nb_phi_would$phi[i], 
                         prob = nb_phi_would$phi[i] / (nb_phi_would$phi[i] + nb_mu_would$mu[i]))
  
  nb_place <- c()
  for (length_val in nb_length) {
    nb_place <- c(nb_place, rtpois(1, nb_lambda_would$lambda[i], a = 0, b = length_val))

  }
  would_generated <- data.frame(nb_length, nb_place)
  would_final <- rbind(would_final, would_generated)
}

```

### Visualization of would final

```{r}
all_df <- data.frame(nb_length = numeric(), nb_place = numeric(), n.x = numeric(), n.y = numeric())
num_iterations <- nrow(would_final) / length(unitlen_would)

for (i in 1:num_iterations) {
  start_index <- (i - 1) * length(unitlen_would) + 1
  end_index <- i * length(unitlen_would)
  
  subset_data <- would_final[start_index:end_index, ] %>% group_by(nb_length, nb_place) %>% count
  
  subset <- subset_data[subset_data$nb_length < 15 & subset_data$nb_length > 1,]
  result <- aggregate(n ~ nb_length, data = subset, FUN = sum)
  
  merged_df <- merge(subset, result, by = "nb_length")
  
  all_df <- rbind(all_df, merged_df)
}

group <- would[c("unitLen", "place")]
colnames(group) <- c("nb_length", "nb_place")

group <- group %>% group_by(nb_length, nb_place) %>% count
subset <- group[group$nb_length < 15 & group$nb_length > 1,]
result <- aggregate(n ~ nb_length, data = subset, FUN = sum)
result <- merge(subset, result, by = "nb_length")

p <- ggplot(data = all_df, aes(x = nb_place, y = n.x/n.y)) +
    geom_point()
  
p + facet_grid(nb_length ~ .) + geom_point(data = result, color = "red") + facet_grid(nb_length ~ .)

```

## an
### Load the data
```{r}
an <- sbc[sbc$transcript == "an", ]

hist(an$unitLen)
hist(he$unitLen)
summary(an$unitLen)
```

### stan model 
```{r}
unitlen_an <- an$unitLen
place_an <- an$unitLen - an$place + t(rep(1, length(unitlen_an)))

an_data <- list(
  N = length(unitlen_an),
  place = place_an,
  unit_length = unitlen_an
)

place_length_nb_an <- stan(
  file = "He_place|length_NB.stan",
  data = an_data,
  chain = 4
)

```

### generate quantities

```{r}
nb_lambda_an <- extract(place_length_nb_an, pars = c("lambda"))
nb_phi_an <- extract(place_length_nb_an, pars = c("phi"))
nb_mu_an <- extract(place_length_nb_an, pars = c("mu"))

an_final = data.frame()
# iterate through 4000 times
for (i in 1:4000) {
  
  
  # generate length
  nb_length <- rztnbinom(length(unitlen_an), size = nb_phi_an$phi[i], 
                         prob = nb_phi_an$phi[i] / (nb_phi_an$phi[i] + nb_mu_an$mu[i]))
  
  nb_place <- c()
  for (length_val in nb_length) {
    nb_place <- c(nb_place, rtpois(1, nb_lambda_an$lambda[i], a = 0, b = length_val))

  }
  an_generated <- data.frame(nb_length, nb_place)
  an_final <- rbind(an_final, an_generated)
}

```

### Visualization of an final
```{r}
all_df <- data.frame(nb_length = numeric(), nb_place = numeric(), n.x = numeric(), n.y = numeric())
num_iterations <- nrow(an_final) / length(unitlen_an)

for (i in 1:num_iterations) {
  start_index <- (i - 1) * length(unitlen_an) + 1
  end_index <- i * length(unitlen_an)
  
  subset_data <- an_final[start_index:end_index, ] %>% group_by(nb_length, nb_place) %>% count
  
  subset <- subset_data[subset_data$nb_length < 15 & subset_data$nb_length > 1,]
  result <- aggregate(n ~ nb_length, data = subset, FUN = sum)
  
  merged_df <- merge(subset, result, by = "nb_length")
  
  all_df <- rbind(all_df, merged_df)
}

group <- an[c("unitLen", "place")]
colnames(group) <- c("nb_length", "nb_place")

group <- group %>% group_by(nb_length, nb_place) %>% count
subset <- group[group$nb_length < 15 & group$nb_length > 1,]
result <- aggregate(n ~ nb_length, data = subset, FUN = sum)
result <- merge(subset, result, by = "nb_length")

p <- ggplot(data = all_df, aes(x = nb_place, y = n.x/n.y)) +
    geom_point()
  
p + facet_grid(nb_length ~ .) + geom_point(data = result, color = "red") + facet_grid(nb_length ~ .)

```

### WAIC
```{r}
library(flexmix)
map_estimates <- map_estimate(place_length_nb_an)[1:3,]

nb_length <- rztnbinom(length(unitlen_an), size = map_estimates[3,2],
                        prob = map_estimates[3,2] / (map_estimates[3,2] + map_estimates[2,2]))
  
nb_place <- c()

for (length_val in nb_length) {
  nb_place <- c(nb_place, rtpois(1, map_estimates[1,2], a = 0, b = length_val))
}

an_sample <- data.frame(nb_length, nb_place)

group_sample <- an_sample %>% group_by(nb_length, nb_place) %>% count

result_sample <- aggregate(n ~ nb_length, data = group_sample, FUN = sum)
result_sample <- merge(group_sample, result_sample, by = "nb_length")

result_sample["prob"] = result_sample$n.x/result_sample$n.y

group <- an[c("unitLen", "place")]
colnames(group) <- c("nb_length", "nb_place")
group_real <- group %>% group_by(nb_length, nb_place) %>% count

result_real <- aggregate(n ~ nb_length, data = group_real, FUN = sum)
result_real <- merge(group_real, result_real, by = "nb_length")

result_real["prob"] = result_real$n.x/result_real$n.y
```


```{r}
library(philentropy)
library(dplyr)
length_unique <- unique(result_real$nb_length)

KLD <- data.frame()
for (length in length_unique) {
  result_real1 <- rep(result_real[result_real$nb_length == length, ]$nb_place, result_real[result_real$nb_length == length, ]$n.x)
  result_sample1 <- rep(result_sample[result_sample$nb_length == length, ]$nb_place, result_sample[result_sample$nb_length == length, ]$n.x)
  
  KL <- data.frame(length, KL(rbind(result_real1,result_sample1), est.prob = "empirical"))
  colnames(KL) <- c("length", "KLD")
  KLD <- rbind(KLD, KL)
  
}

  print(length)
  print(KL(rbind(result_real1,result_sample1), est.prob = "empirical"))
an_final = data.frame()
# iterate through 4000 times

```

